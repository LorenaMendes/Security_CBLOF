{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.base'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3fd48e928ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_checks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise_distances_no_broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.base'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Clustering Based Local Outlier Factor (CBLOF)\n",
    "\"\"\"\n",
    "# Author: Yue Zhao <zhaoy@cmu.edu>\n",
    "#         Shangwen Huang <https://github.com/shangwen777>\n",
    "# License: BSD 2 clause\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "from .base import BaseDetector\n",
    "from ..utils.utility import check_parameter\n",
    "from ..utils.stat_models import pairwise_distances_no_broadcast\n",
    "\n",
    "__all__ = ['CBLOF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseDetector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7ed3af720249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCBLOF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseDetector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"The CBLOF operator calculates the outlier score based on cluster-based\n\u001b[1;32m      3\u001b[0m     \u001b[0mlocal\u001b[0m \u001b[0moutlier\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mCBLOF\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0minput\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseDetector' is not defined"
     ]
    }
   ],
   "source": [
    "class CBLOF(BaseDetector):\n",
    "    \"\"\"The CBLOF operator calculates the outlier score based on cluster-based\n",
    "    local outlier factor.\n",
    "\n",
    "    CBLOF takes as an input the data set and the cluster model that was\n",
    "    generated by a clustering algorithm. It classifies the clusters into small\n",
    "    clusters and large clusters using the parameters alpha and beta.\n",
    "    The anomaly score is then calculated based on the size of the cluster the\n",
    "    point belongs to as well as the distance to the nearest large cluster.\n",
    "\n",
    "    Use weighting for outlier factor based on the sizes of the clusters as\n",
    "    proposed in the original publication. Since this might lead to unexpected\n",
    "    behavior (outliers close to small clusters are not found), it is disabled\n",
    "    by default.Outliers scores are solely computed based on their distance to\n",
    "    the closest large cluster center.\n",
    "\n",
    "    By default, kMeans is used for clustering algorithm instead of\n",
    "    Squeezer algorithm mentioned in the original paper for multiple reasons.\n",
    "\n",
    "    See :cite:`he2003discovering` for details.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int, optional (default=8)\n",
    "        The number of clusters to form as well as the number of\n",
    "        centroids to generate.\n",
    "\n",
    "    contamination : float in (0., 0.5), optional (default=0.1)\n",
    "        The amount of contamination of the data set,\n",
    "        i.e. the proportion of outliers in the data set. Used when fitting to\n",
    "        define the threshold on the decision function.\n",
    "\n",
    "    clustering_estimator : Estimator, optional (default=None)\n",
    "        The base clustering algorithm for performing data clustering.\n",
    "        A valid clustering algorithm should be passed in. The estimator should\n",
    "        have standard sklearn APIs, fit() and predict(). The estimator should\n",
    "        have attributes ``labels_`` and ``cluster_centers_``.\n",
    "        If ``cluster_centers_`` is not in the attributes once the model is fit,\n",
    "        it is calculated as the mean of the samples in a cluster.\n",
    "\n",
    "        If not set, CBLOF uses KMeans for scalability. See\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "    alpha : float in (0.5, 1), optional (default=0.9)\n",
    "        Coefficient for deciding small and large clusters. The ratio\n",
    "        of the number of samples in large clusters to the number of samples in\n",
    "        small clusters.\n",
    "\n",
    "    beta : int or float in (1,), optional (default=5).\n",
    "        Coefficient for deciding small and large clusters. For a list\n",
    "        sorted clusters by size `|C1|, \\|C2|, ..., |Cn|, beta = |Ck|/|Ck-1|`\n",
    "\n",
    "    use_weights : bool, optional (default=False)\n",
    "        If set to True, the size of clusters are used as weights in\n",
    "        outlier score calculation.\n",
    "\n",
    "    check_estimator : bool, optional (default=False)\n",
    "        If set to True, check whether the base estimator is consistent with\n",
    "        sklearn standard.\n",
    "\n",
    "        .. warning::\n",
    "            check_estimator may throw errors with scikit-learn 0.20 above.\n",
    "\n",
    "    random_state : int, RandomState or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random\n",
    "        number generator; If RandomState instance, random_state is the random\n",
    "        number generator; If None, the random number generator is the\n",
    "        RandomState instance used by `np.random`.\n",
    "\n",
    "    n_jobs : integer, optional (default=1)\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        If -1, then the number of jobs is set to the number of cores.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    clustering_estimator_ : Estimator, sklearn instance\n",
    "        Base estimator for clustering.\n",
    "\n",
    "    cluster_labels_ : list of shape (n_samples,)\n",
    "        Cluster assignment for the training samples.\n",
    "\n",
    "    n_clusters_ : int\n",
    "        Actual number of clusters (possibly different from n_clusters).\n",
    "\n",
    "    cluster_sizes_ : list of shape (n_clusters_,)\n",
    "        The size of each cluster once fitted with the training data.\n",
    "\n",
    "    decision_scores_ : numpy array of shape (n_samples,)\n",
    "        The outlier scores of the training data.\n",
    "        The higher, the more abnormal. Outliers tend to have higher scores.\n",
    "        This value is available once the detector is fitted.\n",
    "\n",
    "    cluster_centers_ : numpy array of shape (n_clusters_, n_features)\n",
    "        The center of each cluster.\n",
    "\n",
    "    small_cluster_labels_ : list of clusters numbers\n",
    "        The cluster assignments belonging to small clusters.\n",
    "\n",
    "    large_cluster_labels_ : list of clusters numbers\n",
    "        The cluster assignments belonging to large clusters.\n",
    "\n",
    "    threshold_ : float\n",
    "        The threshold is based on ``contamination``. It is the\n",
    "        ``n_samples * contamination`` most abnormal samples in\n",
    "        ``decision_scores_``. The threshold is calculated for generating\n",
    "        binary outlier labels.\n",
    "\n",
    "    labels_ : int, either 0 or 1\n",
    "        The binary labels of the training data. 0 stands for inliers\n",
    "        and 1 for outliers/anomalies. It is generated by applying\n",
    "        ``threshold_`` on ``decision_scores_``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=8, contamination=0.1,\n",
    "                 clustering_estimator=None, alpha=0.9, beta=5,\n",
    "                 use_weights=False, check_estimator=False, random_state=None,\n",
    "                 n_jobs=1):\n",
    "        super(CBLOF, self).__init__(contamination=contamination)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.clustering_estimator = clustering_estimator\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.use_weights = use_weights\n",
    "        self.check_estimator = check_estimator\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    # noinspection PyIncorrectDocstring\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit detector. y is optional for unsupervised methods.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        y : numpy array of shape (n_samples,), optional (default=None)\n",
    "            The ground truth of the input samples (labels).\n",
    "        \"\"\"\n",
    "\n",
    "        # validate inputs X and y (optional)\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # check parameters\n",
    "        # number of clusters are default to 8\n",
    "        self._validate_estimator(default=KMeans(\n",
    "            n_clusters=self.n_clusters,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=self.n_jobs))\n",
    "\n",
    "        self.clustering_estimator_.fit(X=X, y=y)\n",
    "        # Get the labels of the clustering results\n",
    "        # labels_ is consistent across sklearn clustering algorithms\n",
    "        self.cluster_labels_ = self.clustering_estimator_.labels_\n",
    "        self.cluster_sizes_ = np.bincount(self.cluster_labels_)\n",
    "\n",
    "        # Get the actual number of clusters\n",
    "        self.n_clusters_ = self.cluster_sizes_.shape[0]\n",
    "\n",
    "        if self.n_clusters_ != self.n_clusters:\n",
    "            warnings.warn(\"The chosen clustering for CBLOF forms {0} clusters\"\n",
    "                          \"which is inconsistent with n_clusters ({1}).\".\n",
    "                          format(self.n_clusters_, self.n_clusters))\n",
    "\n",
    "        self._set_cluster_centers(X, n_features)\n",
    "        self._set_small_large_clusters(n_samples)\n",
    "\n",
    "        self.decision_scores_ = self._decision_function(X,\n",
    "                                                        self.cluster_labels_)\n",
    "\n",
    "        self._process_decision_scores()\n",
    "        return self\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Predict raw anomaly score of X using the fitted detector.\n",
    "\n",
    "        The anomaly score of an input sample is computed based on different\n",
    "        detector algorithms. For consistency, outliers are assigned with\n",
    "        larger anomaly scores.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            The training input samples. Sparse matrices are accepted only\n",
    "            if they are supported by the base estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        anomaly_scores : numpy array of shape (n_samples,)\n",
    "            The anomaly score of the input samples.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['decision_scores_', 'threshold_', 'labels_'])\n",
    "        X = check_array(X)\n",
    "        labels = self.clustering_estimator_.predict(X)\n",
    "        return self._decision_function(X, labels)\n",
    "\n",
    "\n",
    "    def _validate_estimator(self, default=None):\n",
    "        \"\"\"Check the value of alpha and beta and clustering algorithm.\n",
    "        \"\"\"\n",
    "        check_parameter(self.alpha, low=0, high=1, param_name='alpha',\n",
    "                        include_left=False, include_right=False)\n",
    "\n",
    "        check_parameter(self.beta, low=1, param_name='beta',\n",
    "                        include_left=False)\n",
    "\n",
    "        if self.clustering_estimator is not None:\n",
    "            self.clustering_estimator_ = self.clustering_estimator\n",
    "        else:\n",
    "            self.clustering_estimator_ = default\n",
    "\n",
    "        # make sure the base clustering algorithm is valid\n",
    "        if self.clustering_estimator_ is None:\n",
    "            raise ValueError(\"clustering algorithm cannot be None\")\n",
    "\n",
    "        if self.check_estimator:\n",
    "            check_estimator(self.clustering_estimator_)\n",
    "\n",
    "    def _set_cluster_centers(self, X, n_features):\n",
    "        # Noted not all clustering algorithms have cluster_centers_\n",
    "        if hasattr(self.clustering_estimator_, 'cluster_centers_'):\n",
    "            self.cluster_centers_ = self.clustering_estimator_.cluster_centers_\n",
    "        else:\n",
    "            # Set the cluster center as the mean of all the samples within\n",
    "            # the cluster\n",
    "            warnings.warn(\"The chosen clustering for CBLOF does not have\"\n",
    "                          \"the center of clusters. Calculate the center\"\n",
    "                          \"as the mean of the clusters.\")\n",
    "            self.cluster_centers_ = np.zeros([self.n_clusters_, n_features])\n",
    "            for i in range(self.n_clusters_):\n",
    "                self.cluster_centers_[i, :] = np.mean(\n",
    "                    X[np.where(self.cluster_labels_ == i)], axis=0)\n",
    "\n",
    "    def _set_small_large_clusters(self, n_samples):\n",
    "        # Sort the index of clusters by the number of samples belonging to it\n",
    "        size_clusters = np.bincount(self.cluster_labels_)\n",
    "\n",
    "        # Sort the order from the largest to the smallest\n",
    "        sorted_cluster_indices = np.argsort(size_clusters * -1)\n",
    "\n",
    "        # Initialize the lists of index that fulfill the requirements by\n",
    "        # either alpha or beta\n",
    "        alpha_list = []\n",
    "        beta_list = []\n",
    "\n",
    "        for i in range(1, self.n_clusters_):\n",
    "            temp_sum = np.sum(size_clusters[sorted_cluster_indices[:i]])\n",
    "            if temp_sum >= n_samples * self.alpha:\n",
    "                alpha_list.append(i)\n",
    "\n",
    "            if size_clusters[sorted_cluster_indices[i - 1]] / size_clusters[\n",
    "                sorted_cluster_indices[i]] >= self.beta:\n",
    "                beta_list.append(i)\n",
    "\n",
    "            # Find the separation index fulfills both alpha and beta\n",
    "        intersection = np.intersect1d(alpha_list, beta_list)\n",
    "\n",
    "        if len(intersection) > 0:\n",
    "            self._clustering_threshold = intersection[0]\n",
    "        elif len(alpha_list) > 0:\n",
    "            self._clustering_threshold = alpha_list[0]\n",
    "        elif len(beta_list) > 0:\n",
    "            self._clustering_threshold = beta_list[0]\n",
    "        else:\n",
    "            raise ValueError(\"Could not form valid cluster separation. Please \"\n",
    "                             \"change n_clusters or change clustering method\")\n",
    "\n",
    "        self.small_cluster_labels_ = sorted_cluster_indices[\n",
    "                                     self._clustering_threshold:]\n",
    "        self.large_cluster_labels_ = sorted_cluster_indices[\n",
    "                                     0:self._clustering_threshold]\n",
    "\n",
    "        # No need to calculate small cluster center\n",
    "        # self.small_cluster_centers_ = self.cluster_centers_[\n",
    "        #     self.small_cluster_labels_]\n",
    "\n",
    "        self._large_cluster_centers = self.cluster_centers_[\n",
    "            self.large_cluster_labels_]\n",
    "\n",
    "    def _decision_function(self, X, labels):\n",
    "        # Initialize the score array\n",
    "        scores = np.zeros([X.shape[0], ])\n",
    "\n",
    "        small_indices = np.where(\n",
    "            np.isin(labels, self.small_cluster_labels_))[0]\n",
    "        large_indices = np.where(\n",
    "            np.isin(labels, self.large_cluster_labels_))[0]\n",
    "\n",
    "        if small_indices.shape[0] != 0:\n",
    "            # Calculate the outlier factor for the samples in small clusters\n",
    "            dist_to_large_center = cdist(X[small_indices, :],\n",
    "                                         self._large_cluster_centers)\n",
    "\n",
    "            scores[small_indices] = np.min(dist_to_large_center, axis=1)\n",
    "\n",
    "        if large_indices.shape[0] != 0:\n",
    "            # Calculate the outlier factor for the samples in large clusters\n",
    "            large_centers = self.cluster_centers_[labels[large_indices]]\n",
    "\n",
    "            scores[large_indices] = pairwise_distances_no_broadcast(\n",
    "                X[large_indices, :], large_centers)\n",
    "\n",
    "        if self.use_weights:\n",
    "            # Weights are calculated as the number of elements in the cluster\n",
    "            scores = scores * self.cluster_sizes_[labels]\n",
    "\n",
    "        return scores.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
